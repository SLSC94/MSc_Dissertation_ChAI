{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WarpedGP.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["-kAswo21XKcz","SvGqTBv6GcP7","YD_6zjvQSMkv","QCRyDRFBr2sx"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bEMnkaTyGo1g","colab_type":"text"},"source":["# Preliminaries"]},{"cell_type":"code","metadata":{"id":"8G32I6kJJMZV","colab_type":"code","outputId":"b707b67a-9c90-434d-9407-81d409c8239a","executionInfo":{"status":"ok","timestamp":1564509305962,"user_tz":-60,"elapsed":4123,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install gpytorch\n","  \n","import math\n","import torch\n","import gpytorch \n","import sklearn\n","from sklearn.feature_selection import mutual_info_regression\n","from matplotlib import pyplot as plt\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gpytorch in /usr/local/lib/python3.6/dist-packages (0.3.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2UqLJswSjdq","colab_type":"code","outputId":"cd84c346-7192-4688-e10b-41e62c93efa1","executionInfo":{"status":"ok","timestamp":1562708448033,"user_tz":-60,"elapsed":22511,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd gdrive/My Drive/MSC Thesis"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive/MSC Thesis\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9qYQu2k8UWmp","colab_type":"code","colab":{}},"source":["import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import datetime\n","\n","predictors = pd.read_csv('pred_inputs.csv')\n","predict_these = np.unique(predictors['INSTRUMENT'])\n","\n","def from_csv(instrument):\n","    df = pd.read_csv('Data/' + instrument + '.csv')\n","    df['date'] = pd.to_datetime(df['date']).dt.date\n","    df.set_index('date',inplace=True)\n","    df = df.sort_values(by = 'date')\n","    df.columns = [instrument]\n","    \n","    return df\n","  \n","def preprocessing(commodity):\n","    #####################################################################################\n","    # This ensures chronological order (some time series are NOT in order)              #\n","    #####################################################################################\n","    \n","    prices_df = db.get_instrument_data(commodity)\n","    prices_df = prices_df.sort_values(by = 'date')\n","    prices_df.columns = [commodity]\n","    return prices_df\n","  \n","def get_predictors(commodity, predictors):\n","    ####################################################################\n","    # This returns the df containing the values of the commodity to be #\n","    # predicted as well as that of its predictors.                     #\n","    #                                                                  #\n","    # Args:                                                            #\n","    # 1) commodity: name of the commodity                              #\n","    # 2) predictors: the dataframe sent by Michael Button              #\n","    ####################################################################\n","    \n","    # get a list of all its predictors\n","    Pred = list(predictors.loc[predictors['INSTRUMENT'] == commodity]['INPUT'])\n","    Pred = [p for p in Pred if p != commodity]\n","    \n","    # Initialize the dataframe with the commodity we want to predict\n","    DF = from_csv( commodity )\n","    \n","    # Keep adding the predictors\n","    for predictor in Pred:\n","        temp_df = from_csv( predictor )\n","        DF = DF.join(temp_df)\n","        \n","    DF.index = pd.to_datetime(DF.index)\n","    return DF\n","  \n","def price_to_returns(prices_df, diff):\n","    ###############################################################\n","    # This changes the price data to 5 day log difference.        #\n","    # If X has negative values, use the following scheme:         # \n","    #          X := X - min(X) + 1                                #\n","    ###############################################################\n","    \n","    # forward fill\n","    prices_df.fillna(method='ffill', inplace = True)\n","    \n","    returns_df = prices_df.copy()\n","    for colname in prices_df.columns:\n","        temp = prices_df.loc[:,colname]\n","        \n","        if np.min(temp) <= 0:\n","            temp = temp - np.min(temp) + 1\n","        returns_df[colname] = np.log(temp) - np.log(temp.shift(diff))\n","\n","    # drop rows with NaN\n","    returns_df.dropna(inplace = True)\n","    return returns_df\n","\n","\n","  \n","def feature_generation(metal, time_pred = [1,5,22]):\n","  metal = metal + '_lme_prices'\n","  Metal_DF = get_predictors(metal, predictors)\n","  # remove comex, since comex is not \n","  Metal_DF = Metal_DF[[col for col in list(Metal_DF.columns) if 'comex' not in col]]\n","  \n","  # 1, 5, 22 days\n","  # log difference L\n","  LD = [price_to_returns(Metal_DF, t_pred) for t_pred in time_pred]\n","\n","  # EWMA of L\n","  # EWMA = [L.ewm(span = horizon).mean() for horizon, L in zip(time_pred, LD)]\n","  EWMA = [LD[0].ewm(halflife = horizon).mean() for horizon in time_pred ]\n","\n","  # EWMV of L\n","  # 1. calculate expanding window mean for the returns (1 day) \n","  # 2. subtract rolling mean and take square\n","  EM = LD[0].expanding(2).mean() \n","  EWMV = [((LD[0] - EM)**2).ewm(span = horizon).mean()**0.5 for horizon in time_pred ]\n","  \n","  # rename columns\n","  for horizon, ld, ewma, ewmv in zip(time_pred, LD, EWMA, EWMV):\n","    ld.columns = [col + '_LD_' + str(horizon) for col in ld.columns]\n","    ewma.columns = [col + '_EWMA_' + str(horizon) for col in ewma.columns]\n","    ewmv.columns = [col + '_EWMV_' + str(horizon) for col in ewmv.columns]\n","    \n","  # merge together \n","  ALL_FEATURES = pd.concat([pd.concat(DFS, axis = 1, sort=True) for DFS in [LD, EWMA, EWMV]], axis = 1)\n","  ALL_FEATURES_columns = list(ALL_FEATURES.columns)\n","  ALL_FEATURES_columns.sort()\n","  ALL_FEATURES = ALL_FEATURES.loc[:,ALL_FEATURES_columns]\n","  ALL_FEATURES.dropna(inplace = True)\n","  \n","  return ALL_FEATURES\n","\n","\n","\n","def feature_extraction(DF, column_name, lag):\n","  # This extracts the relevant predictors for the column_name\n","  # threshold is the % of predictors that we want to include\n","  # Mutual Information\n","  DF_metal = DF.loc[:,[column_name]]\n","  MI_table = np.zeros(DF.shape[1])\n","  for i in range(DF.shape[1]):\n","      MI = sklearn.feature_selection.mutual_info_regression(DF_metal, DF.iloc[:,i])\n","      MI_table[i] = MI\n","  \n","  tol = 1e-3\n","  MI_table_2 = MI_table[MI_table > tol]\n","  out, bins = pd.qcut(MI_table_2, [0.9, 1], retbins=True)\n","  selected_cols = list(MI_table > bins[-2])\n","  \n","  DF = DF.loc[:,selected_cols].shift(periods = lag)\n","  DF.columns = [col + '_lag' for col in DF.columns]\n","  DF = pd.concat([DF_metal, DF], axis = 1, sort = True).dropna()\n","  time_column = pd.DataFrame(index = DF.index, \n","                             data = np.arange(DF.shape[0])*0.01 , \n","                             columns = ['time'] )\n","  DF = pd.concat([DF, time_column], axis = 1)\n","  # add time column\n","  \n","  \n","  return(DF)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZUCTPwUK3Qp","colab_type":"text"},"source":["# 1. Warped GP"]},{"cell_type":"code","metadata":{"id":"AQZkO4X40Hw5","colab_type":"code","outputId":"34f4eb6d-3538-493c-cd9b-a2ec46c9efee","executionInfo":{"status":"ok","timestamp":1562708452771,"user_tz":-60,"elapsed":658,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["A = torch.linspace(1,10,10).view(2,5)\n","B = torch.linspace(1,15,15).view(3,5)\n","\n","\n","torch.norm( (A[:,None,] - A[None,:])/torch.linspace(1,5,5) , dim = 2)\n","torch.norm(torch.tensor([1.,1.]))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.4142)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"FhJHytlhXCzX","colab_type":"text"},"source":["## 1.1 Some helper functions"]},{"cell_type":"code","metadata":{"id":"LzTqzjDnW7TR","colab_type":"code","colab":{}},"source":["def softplus(param):\n","    return torch.log(1 + torch.exp(param) )\n","\n","  \n","def RBF(lengthscale, X1, X2):\n","    if len(X1.shape) == 1:\n","      X1 = torch.unsqueeze(X1, 0)\n","      X2 = torch.unsqueeze(X2, 1)\n","      return torch.exp( -((X1 - X2)/softplus(lengthscale) )**2 )\n","    else:\n","      return torch.exp(-torch.norm((X1[:,None] - X2[None,:])/lengthscale, dim = 2)**2)\n","    \n","      \n","  \n","def Warp(A, B, C, Observations):\n","    f = Variable(torch.zeros(len(Observations)))\n","    for a,b,c in zip(A,B,C):\n","        f += a * torch.tanh(b * (Observations + c))\n","    return (f + Observations)\n","\n","def Warp_derivative(A,B,C, Observations):\n","    df = Variable(torch.zeros(len(Observations)))\n","    for a,b,c in zip(A,B,C):\n","        df += a * (1 - torch.tanh(b * (Observations + c))**2 ) * b\n","    return df+1\n","\n","def Warp_inverse(A,B,C, Latents):\n","    # This function uses the Newton Raphson Method (iterative) which finds the roots of a function f. \n","    # where x1 = x0 - f(x0)/f'(x0)\n","    # Here, our f is defined as f = Latents - warp(observations)\n","    \n","    Observation = torch.randn(size = Latents.shape)\n","    for i in range(10):\n","        Observation += (Latents - Warp(A,B,C, Observation) )/(Warp_derivative(A,B,C, Observation) )\n","    return(Observation)\n","\n","def Warp_inverse_NS(A,B,C, Latents):\n","    #this is a Numerically Stable way of finding the inverse\n","        \n","    if torch.tensor(Latents).shape == torch.Size([]):\n","        Latents = torch.tensor(Latents).unsqueeze(0)\n","      \n","    Inverse = torch.zeros(Latents.shape)\n","\n","    for i,latent in enumerate(Latents):\n","        \n","        #first find the domain of observations corresponding to the latents\n","        init_obs_guess_upper = torch.tensor([10])\n","        init_obs_guess_lower = torch.tensor([-10])\n","        #determine if the domain is positive or negative\n","        if Warp(A,B,C, torch.zeros(1) ) >= latent:\n","            sign = -1.0\n","        else: \n","            sign = 1.0\n","        tol = 1e-6\n","        \n","        \n","        niter = 0\n","        if sign == 1:\n","            top = torch.tensor([sign])\n","            bottom = torch.zeros(1)\n","            # first determine the range [bottom,top] such that latent is in f([bottom,top])\n","            while Warp(A,B,C,top) < latent:\n","                bottom = top\n","                top = 2 * top\n","            \n","            while torch.abs(Warp(A,B,C, top) - latent) >= tol and niter < 100:\n","                niter += 1\n","                upper_domain = Warp(A,B,C, 0.5*(bottom + top) ) \n","                if upper_domain < latent:\n","                    bottom = 0.5* (bottom + top) \n","                elif upper_domain > latent:\n","                    top = 0.5*(bottom + top) \n","                else:\n","                    top = 0.5*(bottom + top) \n","                \n","\n","                    \n","        if sign == -1:\n","            bottom = torch.tensor([sign])\n","            top = torch.zeros(1)\n","            # first determine the range [bottom,top] such that latent is in f([bottom,top])\n","            while Warp(A,B,C,bottom) > latent:\n","                top = bottom\n","                bottom = 2 * bottom\n","                \n","            while torch.abs(Warp(A,B,C, top) - latent) >= tol and niter < 100:\n","                niter +=1\n","                upper_domain = Warp(A,B,C, 0.5*(bottom + top) ) \n","                if upper_domain < latent:\n","                    bottom = 0.5*(bottom + top) \n","                elif upper_domain > latent:\n","                    top = 0.5*(bottom + top) \n","                else:\n","                    top = 0.5*(bottom + top) \n","                \n","                    \n","\n","        Inverse[i] = top\n","    return(Inverse)\n","    \n","\n","def WGP_predict(X_train, X_test, Y_train, A_, B_, C_, Kernel, lengthscale, noise):\n","    K_XX = Kernel(lengthscale, X_train, X_train) + torch.eye(len(X_train))* noise**2\n","    K_Xx = Kernel(lengthscale, X_train, X_test).t()\n","    K_xx = Kernel(lengthscale, X_test, X_test)\n","    \n","    \n","    \n","    #predict the mean\n","    Y_warped = Warp(A_,B_,C_, Y_train) \n","    \n","    pred_mean = K_Xx.mm(torch.inverse(K_XX) ).mm(Y_warped[:,None]).squeeze()\n","    \n","    \n","    \n","    pred_cov = K_xx - K_Xx.mm(torch.inverse(K_XX)).mm(K_Xx.t())\n","\n","    \n","    pred_Y = Warp_inverse_NS(A_,B_,C_,pred_mean)\n","    \n","#     print('max percentage error: ', \n","#           torch.max(torch.abs(pred_mean-Warp(A_,B_,C_,pred_Y))/torch.abs(pred_mean)).detach().numpy())\n","    return(pred_Y, pred_mean)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9jjWwzdY6CU","colab_type":"text"},"source":["## 1.2 Warped GP training functions"]},{"cell_type":"code","metadata":{"id":"d4l6ClAxZLR2","colab_type":"code","colab":{}},"source":["# A, B, C parameterizes the function\n","def WGP_train(X,Y,X_test,Y_test, size = (3,), ARD = False):\n","  A = torch.nn.Parameter(torch.randn(size = size))\n","  B = torch.nn.Parameter(torch.randn(size = size))\n","  C = torch.nn.Parameter(torch.randn(size = size))\n","\n","  \n","  if ARD == False:\n","    lengthscale_param = torch.nn.Parameter(torch.randn(size = (1,)), requires_grad = True)\n","  else:\n","    lengthscale_param = torch.nn.Parameter(torch.randn(size = (X.shape[1],)), requires_grad = True)\n","  \n","  noise_param = torch.nn.Parameter((torch.randn(size = (1,))))\n","\n","  List_params = [A,B,C, lengthscale_param, noise_param]\n","  optimizer = torch.optim.Adam(params = List_params, lr = 0.1)\n","\n","  trials = 50\n","  LLH = np.zeros(trials)\n","  for i in range(trials):\n","      A_ = softplus(A)\n","      B_ = softplus(B)\n","      C_ = C\n","      Kernel = RBF(softplus(lengthscale_param), X, X)+ torch.eye(len(Y))*softplus(noise_param)**2 \n","      # Compute Cholesky decomposition of Kernel\n","      Cholesky = torch.cholesky(Kernel)\n","\n","      Likelihood = 0.5*2*torch.sum(torch.log(torch.diag(Cholesky))) \\\n","              + 0.5* Warp(A_,B_,C_,Y).unsqueeze(0).mm(torch.inverse(Kernel) ).mm(Warp(A_,B_,C_,Y).unsqueeze(1)) \\\n","              - torch.sum(torch.log(Warp_derivative(A_,B_,C_,Y) ))\n","      LLH[i] = Likelihood.detach().numpy()\n","      optimizer.zero_grad()\n","      Likelihood.backward()\n","      optimizer.step()\n","  \n","  pred_Y,pred_mean = WGP_predict(X, X_test, Y, A_, B_, C_, Kernel=RBF, \n","                                lengthscale=softplus(lengthscale_param), noise=softplus(noise_param))\n","  return pred_Y,LLH\n","\n","def WGP_plot_transformation(X,Y,X_test,size = (3,)):\n","  A = torch.nn.Parameter(torch.randn(size = size))\n","  B = torch.nn.Parameter(torch.randn(size = size))\n","  C = torch.nn.Parameter(torch.randn(size = size))\n","\n","  lengthscale_param = torch.nn.Parameter(torch.randn(size = (1,)), requires_grad = True)\n","  noise_param = torch.nn.Parameter((torch.randn(size = (1,))))\n","\n","  List_params = [A,B,C, lengthscale_param, noise_param]\n","  optimizer = torch.optim.Adam(params = List_params, lr = 0.003)\n","\n","  trials = 20000\n","  LLH = np.zeros(trials)\n","  for i in range(trials):\n","      A_ = softplus(A)\n","      B_ = softplus(B)\n","      C_ = C\n","      Kernel = RBF(softplus(lengthscale_param), X, X)+ torch.eye(len(Y))*softplus(noise_param)**2 \n","      # Compute Cholesky decomposition of Kernel\n","      Cholesky = torch.cholesky(Kernel)\n","\n","      Likelihood = 0.5*2*torch.sum(torch.log(torch.diag(Cholesky))) \\\n","              + 0.5* Warp(A_,B_,C_,Y).unsqueeze(0).mm(torch.inverse(Kernel) ).mm(Warp(A_,B_,C_,Y).unsqueeze(1)) \\\n","              - torch.sum(torch.log(Warp_derivative(A_,B_,C_,Y) ))\n","      LLH[i] = Likelihood.detach().numpy()\n","      optimizer.zero_grad()\n","      Likelihood.backward()\n","      optimizer.step()\n","  \n","  return (A_,B_,C_,softplus(lengthscale_param), softplus(noise_param))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"00adWJE5ijwn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwGDZP8AlkTW","colab_type":"text"},"source":["# 2. Vanilla GP"]},{"cell_type":"code","metadata":{"id":"56-xGnVMuPyK","colab_type":"code","colab":{}},"source":["class ExactGPModel(gpytorch.models.ExactGP):\n","    def __init__(self, train_x, train_y, likelihood, kernel):\n","        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n","        self.mean_module = gpytorch.means.ConstantMean()\n","        self.covar_module = gpytorch.kernels.ScaleKernel(kernel)\n","\n","    def forward(self, x):\n","        mean_x = self.mean_module(x)\n","        covar_x = self.covar_module(x)\n","        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n","\n","def GP_train(X,Y, X_test, Y_test, kernel):\n","  # initialize likelihood and model\n","  likelihood = gpytorch.likelihoods.GaussianLikelihood()\n","  model = ExactGPModel(X, Y, likelihood, kernel(ard_num_dims = X.shape[1]))\n","\n","  # Find optimal model hyperparameters\n","  model.train()\n","  likelihood.train()\n","  # Use the adam optimizer\n","  optimizer = torch.optim.Adam([\n","      {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n","  ], lr=0.1)\n","\n","  # \"Loss\" for GPs - the marginal log likelihood\n","  mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n","  training_iter = 100\n","  for i in range(training_iter):\n","      # Zero gradients from previous iteration\n","      optimizer.zero_grad()\n","      # Output from model\n","      output = model(X)\n","      # Calc loss and backprop gradients\n","      loss = -mll(output, Y)\n","      loss.backward()\n","      optimizer.step()\n","  # Get into evaluation (predictive posterior) mode\n","  model.eval()\n","  likelihood.eval()\n","  \n","  # Test points are regularly spaced along [0,1]\n","  # Make predictions by feeding model through likelihood\n","  with torch.no_grad(), gpytorch.settings.fast_pred_var():\n","      test_x = X_test\n","      observed_pred = likelihood(model(test_x))\n","\n","#   return torch.mean((observed_pred.mean - Y_test)**2).numpy()\n","  \n","  return observed_pred.mean"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-kAswo21XKcz","colab_type":"text"},"source":["# 3. Toy Dataset\n","\n","### We will use $f(x) = x^{\\frac{1}{3}}$ as our warping function"]},{"cell_type":"code","metadata":{"id":"yKxfs6fhqjAK","colab_type":"code","outputId":"12eb2ff9-ce46-4542-a072-c2056c54a30e","executionInfo":{"status":"ok","timestamp":1561903883639,"user_tz":-60,"elapsed":837,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":287}},"source":["size = (5,)\n","\n","X = 7 * torch.rand(size = (40,) ) - 3.5\n","Warped_Y = torch.sin(X) +0.1*torch.randn(X.shape, ) \n","\n","#note that we use f(x) = x^{1/3} as the warping function\n","Y = Warped_Y ** 3\n","Warped_Y_max = torch.max(Warped_Y).numpy() \n","Warped_Y_min = torch.min(Warped_Y).numpy() \n","\n","X_test = torch.linspace(-3.5,3.5,30)\n","Y_test = torch.sin(X_test)**3\n","\n","plt.plot(torch.linspace(-3.5,3.5,100).numpy(), \n","        torch.sin(torch.linspace(-3.5,3.5,100)).numpy()**3)\n","\n","plt.plot(X.numpy(),Y.numpy(),'x')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f78fe678198>]"]},"metadata":{"tags":[]},"execution_count":11},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"SvGqTBv6GcP7","colab_type":"text"},"source":["## 3.1 Showing the Learned Transformations"]},{"cell_type":"code","metadata":{"id":"LzCDIjAg9Iys","colab_type":"code","outputId":"8f03cc35-af69-4f5d-c7a0-9780aa481c37","executionInfo":{"status":"ok","timestamp":1561863692803,"user_tz":-60,"elapsed":1134,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["m = 5\n","# A_, B_, C_, _LS, _NP = WGP_plot_transformation(X,Y,X_test,size = (m,))\n","plt.plot( torch.linspace(-1,1,50).numpy(), Warp( A_, B_, C_, torch.linspace(-1,1,50) ).detach().numpy(), label = 'Parameterized Warping')\n","plt.plot( np.linspace(-1,1,50)**3, 1.7*np.linspace(-1,1,50),   label = r'(Scaled) Warping ($1.7x^{1/3}$)')\n","plt.legend()\n","plt.title('Learned Transformations for M = ' + str(m))\n","plt.ylabel(r'$z$')\n","plt.xlabel(r'$y$')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, '$y$')"]},"metadata":{"tags":[]},"execution_count":85},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAY4AAAEYCAYAAABLOxEiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"YD_6zjvQSMkv","colab_type":"text"},"source":["## 3.2 Comparison between Warped GP and GP"]},{"cell_type":"code","metadata":{"id":"DtZCG3v6yEkq","colab_type":"code","outputId":"61bb3c93-6db6-4d00-8d9d-e9afe8435524","executionInfo":{"status":"ok","timestamp":1561847911544,"user_tz":-60,"elapsed":2231592,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["trials = 10\n","M = [1,2,3,5] #the complexity of the transformation approximation\n","\n","GP_errors = np.zeros(trials)\n","WGP_errors = np.zeros((len(M),trials))\n","\n","for i in range(trials):\n","  \n","  X = 7 * torch.rand(size = (40,) ) - 3.5\n","  Warped_Y = torch.sin(X) +0.1*torch.randn(X.shape, ) \n","  Y = Warped_Y ** 3\n","  \n","  \n","  Y_pred = GP_train(X,Y, X_test, Y_test)\n","  GP_errors[i] = torch.mean((Y_pred - Y_test)**2).numpy()\n","  for j,m in enumerate(M):\n","    Y_pred = WGP_train(X,Y, X_test, Y_test, size = (m,))\n","    WGP_errors[j,i] = torch.mean((Y_pred - Y_test)**2).numpy()\n","  \n","  \n","print('Warped GP MSE =', np.mean(WGP_errors, axis = 1))\n","print('GP MSE =', np.mean(GP_errors))\n","\n","print('Warped GP RMSE =', np.sqrt(np.mean(WGP_errors, axis = 1)))\n","print('GP RMSE =', np.sqrt(np.mean(GP_errors)))\n","\n","print('Warped GP SD =', np.std(WGP_errors, axis = 1))\n","print('GP SD =', np.std(GP_errors))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Warped GP MSE = [0.0066476  0.00712369 0.00677736 0.00610486]\n","GP MSE = 0.008297738316468895\n","Warped GP RMSE = [0.0815328  0.08440198 0.08232474 0.07813362]\n","GP RMSE = 0.09109192234478804\n","Warped GP SD = [0.00241267 0.00252566 0.00210192 0.00231001]\n","GP SD = 0.00452623493819088\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7_JseZKyx9_g","colab_type":"text"},"source":["# 4. Commodities Dataset"]},{"cell_type":"code","metadata":{"id":"Fn4HTMsQSZa7","colab_type":"code","colab":{}},"source":["\n","DF_AL = get_predictors('al_lme_prices', predictors)\n","AL = price_to_returns(DF_AL, 5).iloc[:,[0]]\n","\n","DF_CU = get_predictors('cu_lme_prices', predictors)\n","CU = price_to_returns(DF_CU, 1).iloc[:,[0]]\n","\n","# DF_all = pd.merge(DF_AL, DF_CU, how = 'inner', left_index=True, right_index=True)\n","# print(DF_all.columns)\n","\n","# #this is the price data\n","# DF_all = DF_all.loc[:,['al_lme_prices', 'cu_lme_prices']]#, 'ted_x', 'gsci_x']]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TLlhxXyUTheg","colab_type":"code","colab":{}},"source":["# Comparisons of errors (Aluminium)\n","\n","def compare_GP_and_WGP(window, horizon, Target_Variable, kernel, M, trials):\n","  num_datapoints = 50\n","  \n","  WGP_error = np.zeros((len(M), trials))\n","  GP_error = np.zeros(trials)\n","  \n","  WGP_sign = np.zeros((len(M), trials))\n","  GP_sign = np.zeros(trials)\n","  \n","  BM_error = np.zeros(trials)\n","  \n","  # DF generation and feature extraction\n","  DF = feature_generation(Target_Variable[0:2], time_pred = [1,5,22])\n","  DF = feature_extraction(DF, Target_Variable, horizon)\n","    \n","  \n","  # now get X and Y\n","  Y = DF.loc[:,[Target_Variable]]\n","#   X = DF.drop(Target_Variable, axis = 1)\n","  X = Y.shift(horizon).iloc[horizon:,:]\n","  Y = Y.iloc[horizon:,:]\n","  \n","  for j in range(trials):\n","\n","    #start at a random point\n","    START = int(np.random.choice(np.arange(len(Y) - 200),1) )\n","    END = START + window\n","    \n","    X_train = torch.tensor( X.iloc[START:END, :].values , dtype = torch.float32)\n","    X_test = torch.tensor( X.iloc[[(END+horizon-1)], :].values , dtype = torch.float32)\n","    Y_train = torch.tensor( Y.iloc[START:END, :].values.T.squeeze() , dtype = torch.float32)\n","    Y_test = torch.tensor( Y.iloc[[(END+horizon-1)], :].values.T.squeeze() , dtype = torch.float32)\n","\n","    ##############################\n","    for r,m in enumerate(M):\n","      \n","      Y_pred,LLH = WGP_train(X_train,Y_train,X_test,Y_test, size = (m,), ARD = True)\n","      WGP_error[r,j] = ((Y_pred.detach() - Y_test)**2).numpy()\n","      WGP_sign[r,j] = (torch.sign(Y_pred.detach()) == torch.sign(Y_test)).numpy()\n","      \n","    ################################################################\n","\n","    Y_pred = GP_train(X_train,Y_train,X_test,Y_test, kernel)\n","\n","    GP_error[j] = ((Y_pred.detach() - Y_test)**2).numpy()\n","    GP_sign[j] = (torch.sign(Y_pred.detach()) == torch.sign(Y_test)).numpy()\n","    \n","    BM_error[j] =  Y_test.numpy()**2\n","    \n","  return GP_error, WGP_error, GP_sign, WGP_sign, BM_error\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"au6JsYqGB8Vd","colab_type":"code","colab":{}},"source":["\n","\n","def Experiment_returns(T_list, Target_Variables, kernel, M, trials):\n","  for TV,t in zip(Target_Variables,T_list):\n","    GP_error, WGP_error, GP_sign, WGP_sign, BM_error =  compare_GP_and_WGP(window = 100, \n","                                                                           horizon = t, \n","                                                                           Target_Variable = TV, \n","                                                                           kernel = kernel, \n","                                                                           M = M, \n","                                                                           trials = trials)\n","    print('For T+',t)\n","    for i,m in enumerate(M):\n","      print('M = ', m)\n","      print('WGP_MSE = ', np.mean(WGP_error[i,:]))\n","      print('WGP_MSE_STD = ', np.std(WGP_error[i,:]))\n","      print('WGP_RMSE = ', np.mean(WGP_error[i,:])**0.5 )\n","      print('WGP_SIGN =', np.mean(WGP_sign[i,:]))\n","      print(' ')\n","    \n","    print('GP_MSE = ', np.mean(GP_error))\n","    print('GP_MSE_STD = ', np.std(GP_error))\n","    print('GP_RMSE = ', np.mean(GP_error)**0.5 )\n","    print('GP_SIGN =', np.mean(GP_sign))\n","    print(' ' )\n","    print('BM_MSE = ', np.mean(BM_error))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qk0m7ROqryUR","colab_type":"text"},"source":["# With All features"]},{"cell_type":"code","metadata":{"id":"D6MKTC_KS_Lw","colab_type":"code","outputId":"990e96df-0a76-4ef0-bd29-6cb0eddbf7e5","executionInfo":{"status":"ok","timestamp":1562694275470,"user_tz":-60,"elapsed":1334200,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["Experiment_returns(T_list = [1,5,22], Target_Variables= ['al_lme_prices_LD_1', 'al_lme_prices_LD_5', 'al_lme_prices_LD_22'], kernel = gpytorch.kernels.RBFKernel, M = [2,3,5], trials = 200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 1\n","M =  2\n","WGP_MSE =  0.00018024213243843\n","WGP_MSE_STD =  0.00037261703450334896\n","WGP_RMSE =  0.013425428575596013\n","WGP_SIGN = 0.52\n"," \n","M =  3\n","WGP_MSE =  0.00018892952896413628\n","WGP_MSE_STD =  0.0003860068466911566\n","WGP_RMSE =  0.013745163839115788\n","WGP_SIGN = 0.53\n"," \n","M =  5\n","WGP_MSE =  0.00018847063635724518\n","WGP_MSE_STD =  0.0003825354334852831\n","WGP_RMSE =  0.013728460815300643\n","WGP_SIGN = 0.48\n"," \n","GP_MSE =  0.00017935458029290528\n","GP_MSE_STD =  0.00038228945134502945\n","GP_RMSE =  0.013392332892103051\n","GP_SIGN = 0.48\n"," \n","BM_MSE =  0.00017389356920848086\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 5\n","M =  2\n","WGP_MSE =  0.002128470996860115\n","WGP_MSE_STD =  0.003698195685776343\n","WGP_RMSE =  0.04613535517214661\n","WGP_SIGN = 0.49\n"," \n","M =  3\n","WGP_MSE =  0.0017618496415988919\n","WGP_MSE_STD =  0.0025952981550973983\n","WGP_RMSE =  0.041974392688863195\n","WGP_SIGN = 0.505\n"," \n","M =  5\n","WGP_MSE =  0.00197223539597843\n","WGP_MSE_STD =  0.0035232712390823517\n","WGP_RMSE =  0.044409856968677906\n","WGP_SIGN = 0.49\n"," \n","GP_MSE =  0.0012193997029607661\n","GP_MSE_STD =  0.0023356404268861544\n","GP_RMSE =  0.03491990410869947\n","GP_SIGN = 0.475\n"," \n","BM_MSE =  0.0009313923654965973\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 22\n","M =  2\n","WGP_MSE =  0.011453252108759724\n","WGP_MSE_STD =  0.018140475535410545\n","WGP_RMSE =  0.10701986782256706\n","WGP_SIGN = 0.52\n"," \n","M =  3\n","WGP_MSE =  0.008346924609140185\n","WGP_MSE_STD =  0.013207176124740254\n","WGP_RMSE =  0.09136150507265182\n","WGP_SIGN = 0.495\n"," \n","M =  5\n","WGP_MSE =  0.006769672547684707\n","WGP_MSE_STD =  0.0100621525932312\n","WGP_RMSE =  0.08227801983327447\n","WGP_SIGN = 0.52\n"," \n","GP_MSE =  0.01196529134036659\n","GP_MSE_STD =  0.019635848121906056\n","GP_RMSE =  0.10938597414827272\n","GP_SIGN = 0.455\n"," \n","BM_MSE =  0.004185150120385033\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cIG52Q3cYUqN","colab_type":"code","outputId":"c6a869c4-75d1-44f1-8347-ec8d0632ba4a","executionInfo":{"status":"ok","timestamp":1562709867236,"user_tz":-60,"elapsed":1392773,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["Experiment_returns(T_list = [1,5,22], Target_Variables= ['cu_lme_prices_LD_1', 'cu_lme_prices_LD_5', 'cu_lme_prices_LD_22'], kernel = gpytorch.kernels.RBFKernel, M = [2,3,5], trials = 200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 1\n","M =  2\n","WGP_MSE =  0.00028845433216036497\n","WGP_MSE_STD =  0.0005793735629180618\n","WGP_RMSE =  0.016983943363081642\n","WGP_SIGN = 0.53\n"," \n","M =  3\n","WGP_MSE =  0.00028516880417853494\n","WGP_MSE_STD =  0.00056577660834176\n","WGP_RMSE =  0.016886941824336782\n","WGP_SIGN = 0.52\n"," \n","M =  5\n","WGP_MSE =  0.0002875856846742411\n","WGP_MSE_STD =  0.000573788403102407\n","WGP_RMSE =  0.016958351472777095\n","WGP_SIGN = 0.53\n"," \n","GP_MSE =  0.0002749435992063079\n","GP_MSE_STD =  0.0005777025296566684\n","GP_RMSE =  0.016581423316660963\n","GP_SIGN = 0.48\n"," \n","BM_MSE =  0.0002576017871266778\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 5\n","M =  2\n","WGP_MSE =  0.003202109332298875\n","WGP_MSE_STD =  0.0048671530028471235\n","WGP_RMSE =  0.056587183463209005\n","WGP_SIGN = 0.475\n"," \n","M =  3\n","WGP_MSE =  0.0028989432871605915\n","WGP_MSE_STD =  0.004209777496034997\n","WGP_RMSE =  0.053841835845006174\n","WGP_SIGN = 0.465\n"," \n","M =  5\n","WGP_MSE =  0.0023530304740606313\n","WGP_MSE_STD =  0.0036027130604402192\n","WGP_RMSE =  0.048508045457023224\n","WGP_SIGN = 0.5\n"," \n","GP_MSE =  0.0019025238651842803\n","GP_MSE_STD =  0.0031559051967597453\n","GP_RMSE =  0.04361793054678638\n","GP_SIGN = 0.475\n"," \n","BM_MSE =  0.0011325626603090376\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 22\n","M =  2\n","WGP_MSE =  0.018428784068545614\n","WGP_MSE_STD =  0.03158133127734583\n","WGP_RMSE =  0.13575265768501776\n","WGP_SIGN = 0.515\n"," \n","M =  3\n","WGP_MSE =  0.013499556656817617\n","WGP_MSE_STD =  0.028566761458361584\n","WGP_RMSE =  0.11618759252526759\n","WGP_SIGN = 0.47\n"," \n","M =  5\n","WGP_MSE =  0.01106110498751633\n","WGP_MSE_STD =  0.02366078844206461\n","WGP_RMSE =  0.10517178798288222\n","WGP_SIGN = 0.515\n"," \n","GP_MSE =  0.019346840467598554\n","GP_MSE_STD =  0.040564520865392695\n","GP_RMSE =  0.13909292026411177\n","GP_SIGN = 0.475\n"," \n","BM_MSE =  0.007811189810890368\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QCRyDRFBr2sx","colab_type":"text"},"source":["# With Naive features"]},{"cell_type":"code","metadata":{"id":"4eWJ6Z8rvQz3","colab_type":"code","outputId":"38fbd7cf-4dcf-4d47-8646-cbf99f525529","executionInfo":{"status":"ok","timestamp":1562710869290,"user_tz":-60,"elapsed":933336,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["Experiment_returns(T_list = [1,5,22], Target_Variables= ['al_lme_prices_LD_1', 'al_lme_prices_LD_5', 'al_lme_prices_LD_22'], kernel = gpytorch.kernels.RBFKernel, M = [2,3,5], trials = 200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 1\n","M =  2\n","WGP_MSE =  0.00028113065631651225\n","WGP_MSE_STD =  0.000508190785432998\n","WGP_RMSE =  0.016766951312522864\n","WGP_SIGN = 0.495\n"," \n","M =  3\n","WGP_MSE =  0.00028169092559663755\n","WGP_MSE_STD =  0.0005090326868485751\n","WGP_RMSE =  0.016783650544402954\n","WGP_SIGN = 0.515\n"," \n","M =  5\n","WGP_MSE =  0.00028047924074787014\n","WGP_MSE_STD =  0.0005078855976632767\n","WGP_RMSE =  0.016747514464775664\n","WGP_SIGN = 0.51\n"," \n","GP_MSE =  0.00027238198728416483\n","GP_MSE_STD =  0.00047689505213957013\n","GP_RMSE =  0.016503999130034055\n","GP_SIGN = 0.525\n"," \n","BM_MSE =  0.0002758940482295724\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 5\n","M =  2\n","WGP_MSE =  0.0010983768538853488\n","WGP_MSE_STD =  0.0024475177060379705\n","WGP_RMSE =  0.03314176902166432\n","WGP_SIGN = 0.51\n"," \n","M =  3\n","WGP_MSE =  0.0010821578960813262\n","WGP_MSE_STD =  0.0023202381752195946\n","WGP_RMSE =  0.0328961684103381\n","WGP_SIGN = 0.52\n"," \n","M =  5\n","WGP_MSE =  0.0010843469082532286\n","WGP_MSE_STD =  0.002311539451218718\n","WGP_RMSE =  0.03292942313878621\n","WGP_SIGN = 0.52\n"," \n","GP_MSE =  0.0010904644816258258\n","GP_MSE_STD =  0.0023198320891786306\n","GP_RMSE =  0.033022181660602404\n","GP_SIGN = 0.53\n"," \n","BM_MSE =  0.0011137354572383273\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 22\n","M =  2\n","WGP_MSE =  0.005804086247797669\n","WGP_MSE_STD =  0.009977203049967513\n","WGP_RMSE =  0.07618455386623767\n","WGP_SIGN = 0.56\n"," \n","M =  3\n","WGP_MSE =  0.006092592238688627\n","WGP_MSE_STD =  0.010153791095267777\n","WGP_RMSE =  0.07805505902046726\n","WGP_SIGN = 0.54\n"," \n","M =  5\n","WGP_MSE =  0.006141865284669166\n","WGP_MSE_STD =  0.010321674666541656\n","WGP_RMSE =  0.07837005349410682\n","WGP_SIGN = 0.54\n"," \n","GP_MSE =  0.005629003812255178\n","GP_MSE_STD =  0.009586597033106114\n","GP_RMSE =  0.07502668733360934\n","GP_SIGN = 0.53\n"," \n","BM_MSE =  0.003921141136771453\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3WhUfmI_xUbI","colab_type":"code","outputId":"37bb38d4-26e9-42a0-e4f4-6e044dd03d10","executionInfo":{"status":"ok","timestamp":1562711785168,"user_tz":-60,"elapsed":1833521,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["Experiment_returns(T_list = [1,5,22], Target_Variables= ['cu_lme_prices_LD_1', 'cu_lme_prices_LD_5', 'cu_lme_prices_LD_22'], kernel = gpytorch.kernels.RBFKernel, M = [2,3,5], trials = 200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 1\n","M =  2\n","WGP_MSE =  0.00029007501353119623\n","WGP_MSE_STD =  0.0011735636514734863\n","WGP_RMSE =  0.01703158869663063\n","WGP_SIGN = 0.475\n"," \n","M =  3\n","WGP_MSE =  0.000286359349077534\n","WGP_MSE_STD =  0.001141179942332123\n","WGP_RMSE =  0.016922155568293715\n","WGP_SIGN = 0.48\n"," \n","M =  5\n","WGP_MSE =  0.00029017660103908076\n","WGP_MSE_STD =  0.0011463999300991554\n","WGP_RMSE =  0.01703457076180908\n","WGP_SIGN = 0.465\n"," \n","GP_MSE =  0.0002958767804581735\n","GP_MSE_STD =  0.0011393236949509688\n","GP_RMSE =  0.017201069166135386\n","GP_SIGN = 0.465\n"," \n","BM_MSE =  0.00029824694892342573\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 5\n","M =  2\n","WGP_MSE =  0.0013174070017293689\n","WGP_MSE_STD =  0.0020161317469900145\n","WGP_RMSE =  0.03629610174287824\n","WGP_SIGN = 0.5\n"," \n","M =  3\n","WGP_MSE =  0.0013234560958914948\n","WGP_MSE_STD =  0.0020391545955311258\n","WGP_RMSE =  0.03637933611119772\n","WGP_SIGN = 0.49\n"," \n","M =  5\n","WGP_MSE =  0.001305169879963799\n","WGP_MSE_STD =  0.0020022314522065267\n","WGP_RMSE =  0.0361271349537131\n","WGP_SIGN = 0.48\n"," \n","GP_MSE =  0.0013093281594009376\n","GP_MSE_STD =  0.0020304476240202715\n","GP_RMSE =  0.036184639826878716\n","GP_SIGN = 0.475\n"," \n","BM_MSE =  0.001150226449918108\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 22\n","M =  2\n","WGP_MSE =  0.006878417507392242\n","WGP_MSE_STD =  0.013726201984156177\n","WGP_RMSE =  0.08293622554343935\n","WGP_SIGN = 0.54\n"," \n","M =  3\n","WGP_MSE =  0.007004955303545153\n","WGP_MSE_STD =  0.013331681997574054\n","WGP_RMSE =  0.08369561101721615\n","WGP_SIGN = 0.53\n"," \n","M =  5\n","WGP_MSE =  0.006865469240180923\n","WGP_MSE_STD =  0.012586038791823996\n","WGP_RMSE =  0.08285812718243711\n","WGP_SIGN = 0.53\n"," \n","GP_MSE =  0.006264326895674514\n","GP_MSE_STD =  0.013346628908901113\n","GP_RMSE =  0.07914750088078912\n","GP_SIGN = 0.55\n"," \n","BM_MSE =  0.00486780404187817\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fotXbXDM-0Gt","colab_type":"text"},"source":["# Significance Testing"]},{"cell_type":"code","metadata":{"id":"oBPabntcxYQ1","colab_type":"code","outputId":"c463b8ce-3b3c-480d-b939-ec2503bca6f5","executionInfo":{"status":"ok","timestamp":1562717337172,"user_tz":-60,"elapsed":1486559,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":523}},"source":["Experiment_returns(T_list = [22], Target_Variables= ['al_lme_prices_LD_22'], \n","                   kernel = gpytorch.kernels.RBFKernel, M = [2,3,5], trials = 1000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["For T+ 22\n","M =  2\n","WGP_MSE =  0.00587182349443386\n","WGP_MSE_STD =  0.010361090449851005\n","WGP_RMSE =  0.07662782454457297\n","WGP_SIGN = 0.564\n"," \n","M =  3\n","WGP_MSE =  0.006092120109506823\n","WGP_MSE_STD =  0.010904489499359966\n","WGP_RMSE =  0.07805203462759201\n","WGP_SIGN = 0.567\n"," \n","M =  5\n","WGP_MSE =  0.005742730631973608\n","WGP_MSE_STD =  0.009864315050089929\n","WGP_RMSE =  0.07578080648801257\n","WGP_SIGN = 0.567\n"," \n","GP_MSE =  0.005439792639385043\n","GP_MSE_STD =  0.00969347746428196\n","GP_RMSE =  0.07375494993141167\n","GP_SIGN = 0.59\n"," \n","BM_MSE =  0.004581105389448539\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UIoiB1sk_Pmk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}