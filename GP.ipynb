{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GP_Standard.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["BMs7OcNwA4cm","FhWHgn0qBEGq","52UquWIrWqu1","DL5IDUFfarmG","HbexIfJEd474"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BMs7OcNwA4cm","colab_type":"text"},"source":["# **Mount the Drive and change the working directory:**"]},{"cell_type":"code","metadata":{"id":"L2rG1354-o2d","colab_type":"code","outputId":"2af32241-4d01-4c26-b296-0216a20c3663","executionInfo":{"status":"ok","timestamp":1566587277586,"user_tz":-60,"elapsed":22128,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","%cd gdrive/My Drive/MSC Thesis"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive/MSC Thesis\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FhWHgn0qBEGq","colab_type":"text"},"source":["# Import Required Modules"]},{"cell_type":"code","metadata":{"id":"qmyHBjZJAUOI","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import datetime\n","import sklearn\n","from sklearn.feature_selection import mutual_info_regression\n","\n","predictors = pd.read_csv('pred_inputs.csv')\n","predict_these = np.unique(predictors['INSTRUMENT'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"52UquWIrWqu1","colab_type":"text"},"source":["# Functions for preprocessing and Feature Generation"]},{"cell_type":"code","metadata":{"id":"lFrWx8gkAq2j","colab_type":"code","colab":{}},"source":["def from_csv(instrument):\n","    df = pd.read_csv('Data/' + instrument + '.csv')\n","    df['date'] = pd.to_datetime(df['date']).dt.date\n","    df.set_index('date',inplace=True)\n","    df = df.sort_values(by = 'date')\n","    df.columns = [instrument]\n","    return df\n","  \n","def preprocessing(commodity):\n","    #####################################################################################\n","    # This ensures chronological order (some time series are NOT in order)              #\n","    #####################################################################################\n","    \n","    prices_df = db.get_instrument_data(commodity)\n","    prices_df = prices_df.sort_values(by = 'date')\n","    prices_df.columns = [commodity]\n","    return prices_df\n","  \n","def get_predictors(commodity, predictors):\n","    ####################################################################\n","    # This returns the df containing the values of the commodity to be #\n","    # predicted as well as that of its predictors.                     #\n","    #                                                                  #\n","    # Args:                                                            #\n","    # 1) commodity: name of the commodity                              #\n","    # 2) predictors: the dataframe sent by Michael Button              #\n","    ####################################################################\n","    \n","    # get a list of all its predictors\n","    Pred = list(predictors.loc[predictors['INSTRUMENT'] == commodity]['INPUT'])\n","    Pred = [p for p in Pred if p != commodity]\n","    \n","    # Initialize the dataframe with the commodity we want to predict\n","    DF = from_csv( commodity )\n","    \n","    # Keep adding the predictors\n","    for predictor in Pred:\n","        temp_df = from_csv( predictor )\n","        DF = DF.join(temp_df)\n","    return DF\n","  \n","def price_to_returns(prices_df, diff):\n","    ###############################################################\n","    # This changes the price data to 5 day log difference.        #\n","    # If X has negative values, use the following scheme:         # \n","    #          X := X - min(X) + 1                                #\n","    ###############################################################\n","    \n","    # forward fill\n","    prices_df.fillna(method='ffill', inplace = True)\n","    \n","    returns_df = prices_df.copy()\n","    for colname in prices_df.columns:\n","        temp = prices_df.loc[:,colname]\n","        \n","        if np.min(temp) <= 0:\n","            temp = temp - np.min(temp) + 1\n","        returns_df[colname] = np.log(temp) - np.log(temp.shift(diff))\n","\n","    # drop rows with NaN\n","    returns_df.dropna(inplace = True)\n","    return returns_df\n","  \n","  \n","def feature_generation(metal, time_pred = [1,5,22]):\n","  metal = metal + '_lme_prices'\n","  Metal_DF = get_predictors(metal, predictors)\n","  # remove comex, since comex is not \n","  Metal_DF = Metal_DF[[col for col in list(Metal_DF.columns) if 'comex' not in col]]\n","  \n","  # 1, 5, 22 days\n","  # log difference L\n","  LD = [price_to_returns(Metal_DF, t_pred) for t_pred in time_pred]\n","\n","  # EWMA of L\n","  # EWMA = [L.ewm(span = horizon).mean() for horizon, L in zip(time_pred, LD)]\n","  EWMA = [LD[0].ewm(halflife = horizon).mean() for horizon in time_pred ]\n","\n","  # EWMV of L\n","  # 1. calculate expanding window mean for the returns (1 day) \n","  # 2. subtract rolling mean and take square\n","  EM = LD[0].expanding(2).mean() \n","  EWMV = [((LD[0] - EM)**2).ewm(span = horizon).mean()**0.5 for horizon in time_pred ]\n","  \n","  # rename columns\n","  for horizon, ld, ewma, ewmv in zip(time_pred, LD, EWMA, EWMV):\n","    ld.columns = [col + '_LD_' + str(horizon) for col in ld.columns]\n","    ewma.columns = [col + '_EWMA_' + str(horizon) for col in ewma.columns]\n","    ewmv.columns = [col + '_EWMV_' + str(horizon) for col in ewmv.columns]\n","    \n","  # merge together \n","  ALL_FEATURES = pd.concat([pd.concat(DFS, axis = 1, sort=True) for DFS in [LD, EWMA, EWMV]], axis = 1)\n","  ALL_FEATURES_columns = list(ALL_FEATURES.columns)\n","  ALL_FEATURES_columns.sort()\n","  ALL_FEATURES = ALL_FEATURES.loc[:,ALL_FEATURES_columns]\n","  ALL_FEATURES.dropna(inplace = True)\n","  \n","  return ALL_FEATURES\n","\n","\n","\n","def feature_extraction(DF, column_name, lag):\n","  # This extracts the relevant predictors for the column_name\n","  # threshold is the % of predictors that we want to include\n","  # Mutual Information\n","  DF_metal = DF.loc[:,[column_name]]\n","  MI_table = np.zeros(DF.shape[1])\n","  for i in range(DF.shape[1]):\n","      MI = sklearn.feature_selection.mutual_info_regression(DF_metal, DF.iloc[:,i])\n","      MI_table[i] = MI\n","  \n","  tol = 1e-3\n","  MI_table_2 = MI_table[MI_table > tol]\n","  out, bins = pd.qcut(MI_table_2, [0.9, 1], retbins=True)\n","  selected_cols = list(MI_table > bins[-2])\n","  \n","  DF = DF.loc[:,selected_cols].shift(periods = lag)\n","  DF.columns = [col + '_lag' for col in DF.columns]\n","  DF = pd.concat([DF_metal, DF], axis = 1, sort = True).dropna()\n","  time_column = pd.DataFrame(index = DF.index, \n","                             data = np.arange(DF.shape[0])*0.1 , \n","                             columns = ['time'] )\n","  DF = pd.concat([DF, time_column], axis = 1)\n","  # add time column\n","  \n","  \n","  return(DF)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4GqosxqYFSd","colab_type":"code","colab":{}},"source":["DF = feature_generation('al', time_pred = [1,5,22])\n","DF = feature_extraction(DF, 'al_lme_prices_LD_1',1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DL5IDUFfarmG","colab_type":"text"},"source":["# Import GPytorch"]},{"cell_type":"code","metadata":{"id":"u4oAmFk9amCt","colab_type":"code","outputId":"f1bfb656-1219-4083-8dd4-5da2e02ace55","executionInfo":{"status":"ok","timestamp":1566587315985,"user_tz":-60,"elapsed":12134,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":214}},"source":["!pip install gpytorch\n","import torch\n","import gpytorch "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting gpytorch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/e4/e74dc12c6d07a5d8628dfb573b01297f7c2b44eec524be4b401c0782d39c/gpytorch-0.3.5.tar.gz (211kB)\n","\u001b[K     |████████████████████████████████| 215kB 5.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: gpytorch\n","  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpytorch: filename=gpytorch-0.3.5-py2.py3-none-any.whl size=349719 sha256=cea5b1cc91f00e2d7a6fc0a232a566e5072087087fb12c5af6dae3c7b2ddd830\n","  Stored in directory: /root/.cache/pip/wheels/d6/31/88/c43a94e0073a54056ac663366f2195de36535b38a81a378196\n","Successfully built gpytorch\n","Installing collected packages: gpytorch\n","Successfully installed gpytorch-0.3.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HbexIfJEd474","colab_type":"text"},"source":["# Get Gpytorch model ExactGPModel"]},{"cell_type":"code","metadata":{"id":"svGoSrJreaof","colab_type":"code","colab":{}},"source":["class ExactGPModel(gpytorch.models.ExactGP):\n","    def __init__(self, train_x, train_y, likelihood, kernel):\n","        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n","        self.mean_module = gpytorch.means.ConstantMean()\n","        self.covar_module = gpytorch.kernels.ScaleKernel(kernel)\n","\n","    def forward(self, x):\n","        mean_x = self.mean_module(x)\n","        covar_x = self.covar_module(x)\n","        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yQyH8qURaHhz","colab_type":"text"},"source":["# First do Aluminium"]},{"cell_type":"code","metadata":{"id":"4-mXgTLlZarS","colab_type":"code","colab":{}},"source":["Windows = [50, 100, 150]\n","Horizons = [1, 5, 22]\n","AL_Target_Variables = ['al_lme_prices_LD_1', 'al_lme_prices_LD_5', 'al_lme_prices_LD_22']\n","Kernels = [gpytorch.kernels.RBFKernel, gpytorch.kernels.MaternKernel]\n","trials = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYOSfOpxbKeB","colab_type":"code","colab":{}},"source":["\n","def GET_STAT(metal, Windows, Horizons, Target_Variables, Kernels, trials):\n","\n","  # metal is either 'al' or 'cu'\n","  \n","  I = len(Horizons)\n","  J = len(Kernels)\n","  K = len(Windows)\n","  \n","  MSE = np.zeros((I,J,K,trials))\n","  DIR = np.zeros((I,J,K,trials))\n","  BM = np.zeros((I,J,K,trials))\n","\n","  for i,H_TV in enumerate(zip(Horizons, Target_Variables)):\n","    # horizon and target variable\n","    H = H_TV[0]\n","    TV = H_TV[1]\n","    \n","    DF = feature_generation(metal, time_pred = [1,5,22])\n","    DF = feature_extraction(DF, TV, H)\n","    \n","    \n","    # X is the predictors - all but the first column\n","    X = DF.iloc[:,1:]\n","    \n","    # Y is the target variable - just the first column\n","    Y = DF.iloc[:,[0]]\n","    \n","    ard_param = X.shape[1]\n","\n","    for j,Kernel in enumerate(Kernels):\n","      for k,Window in enumerate(Windows):\n","        for t in range(trials):\n","\n","          START = int(np.random.choice(np.arange(len(Y) - 200),1) )\n","          END = START + Window\n","          X_train = torch.tensor( X.iloc[START:END, :].values , dtype = torch.float32)\n","          X_test = torch.tensor( X.iloc[[END -1 + H], :].values , dtype = torch.float32)\n","          Y_train = torch.tensor( Y.iloc[START:END, :].values.T.squeeze() , dtype = torch.float32)\n","          Y_test = torch.tensor( Y.iloc[END -1 + H, :].values.T.squeeze() , dtype = torch.float32)\n","\n","          likelihood = gpytorch.likelihoods.GaussianLikelihood()\n","          model = ExactGPModel(X_train, Y_train, likelihood, Kernel(ard_num_dims = ard_param))\n","          model.train()\n","          likelihood.train()\n","\n","          # Use the adam optimizer\n","          optimizer = torch.optim.Adam([\n","              {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n","          ], lr=0.1)\n","\n","          # \"Loss\" for GPs - the marginal log likelihood\n","          mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n","          training_iter = 100\n","          for l in range(training_iter):\n","              optimizer.zero_grad()\n","              output = model(X_train)\n","              loss = -mll(output, Y_train)\n","              loss.backward()\n","              optimizer.step()\n","\n","          # Get into evaluation (predictive posterior) mode\n","          model.eval()\n","          likelihood.eval()\n","\n","          # Make predictions by feeding model through likelihood\n","          with torch.no_grad(), gpytorch.settings.fast_pred_var():\n","              observed_pred = likelihood(model(X_test))\n","\n","          MSE[i,j,k,t] = (observed_pred.mean - Y_test).numpy()**2\n","          DIR[i,j,k,t] = (torch.sign(observed_pred.mean) == torch.sign(Y_test)).numpy()\n","          BM[i,j,k,t] = Y_test.numpy()**2\n","\n","        print(TV, ', Kernel = ', str(Kernel),', Window = ', Window)\n","        print('MSE = ', np.mean(MSE[i,j,k,:]), \n","              ', RMSE = ', np.mean(MSE[i,j,k,:])**0.5, \n","              ', DIR = ', np.mean(DIR[i,j,k,:]), \n","              ', BENCHMARK = ', np.mean(BM[i,j,k,:]))\n","        print(' ')\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZtlGvrfdTEg","colab_type":"code","outputId":"b3279365-2196-43f2-8f87-823f84d19d8a","executionInfo":{"status":"ok","timestamp":1562563237220,"user_tz":-60,"elapsed":55236,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["GET_STAT('al',Windows, Horizons, AL_Target_Variables,Kernels, trials = 50)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["al_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.0019729890278808605 , RMSE =  0.04441834112031719 , DIR =  0.54 , BENCHMARK =  0.001313752518315141\n"," \n","al_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  100\n","MSE =  0.0011453146558780957 , RMSE =  0.03384249777835696 , DIR =  0.54 , BENCHMARK =  0.0005588095442554675\n"," \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lMGNDC4ShgAC","colab_type":"code","colab":{}},"source":["CU_Target_Variables = ['cu_lme_prices_LD_1', 'cu_lme_prices_LD_5', 'cu_lme_prices_LD_22']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aW0h8s9937XG","colab_type":"code","outputId":"784f42aa-fde5-49aa-8302-21bbf308a120","executionInfo":{"status":"ok","timestamp":1562291130899,"user_tz":-60,"elapsed":768785,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":989}},"source":["GET_STAT('cu',Windows, Horizons, CU_Target_Variables,Kernels, trials = 200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cu_lme_prices_LD_1 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  50\n","MSE =  0.00033432182600737036 , RMSE =  0.018284469530379335 , DIR =  0.44 , BENCHMARK =  0.0003308569215924928\n"," \n","cu_lme_prices_LD_1 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.00025950302456800856 , RMSE =  0.01610909757149694 , DIR =  0.46 , BENCHMARK =  0.00020334807407484056\n"," \n","cu_lme_prices_LD_1 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  150\n","MSE =  0.00025917402156238126 , RMSE =  0.016098882618442226 , DIR =  0.48 , BENCHMARK =  0.0002232598571414357\n"," \n","cu_lme_prices_LD_1 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  50\n","MSE =  0.0003215299935250204 , RMSE =  0.017931257444056187 , DIR =  0.505 , BENCHMARK =  0.00026824460024839846\n"," \n","cu_lme_prices_LD_1 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  100\n","MSE =  0.0003218717211001776 , RMSE =  0.01794078373706616 , DIR =  0.45 , BENCHMARK =  0.0002648403321524917\n"," \n","cu_lme_prices_LD_1 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  150\n","MSE =  0.0003979789944737622 , RMSE =  0.019949410880368428 , DIR =  0.42 , BENCHMARK =  0.0002936981885659706\n"," \n","cu_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  50\n","MSE =  0.001782032022570137 , RMSE =  0.04221412112753429 , DIR =  0.43 , BENCHMARK =  0.001274517532980113\n"," \n","cu_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.0013429254494694298 , RMSE =  0.03664594724481044 , DIR =  0.515 , BENCHMARK =  0.0012146537682842995\n"," \n","cu_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  150\n","MSE =  0.0013178919040942106 , RMSE =  0.03630278094160571 , DIR =  0.47 , BENCHMARK =  0.001127739525541398\n"," \n","cu_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  50\n","MSE =  0.0014383903688073474 , RMSE =  0.037926117238749175 , DIR =  0.495 , BENCHMARK =  0.000987724995689585\n"," \n","cu_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  100\n","MSE =  0.0016927318173152984 , RMSE =  0.041142822184620474 , DIR =  0.45 , BENCHMARK =  0.0012708444658707041\n"," \n","cu_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  150\n","MSE =  0.0012992532545123936 , RMSE =  0.036045155770399906 , DIR =  0.52 , BENCHMARK =  0.0010760050778366615\n"," \n","cu_lme_prices_LD_22 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  50\n","MSE =  0.009108632495810233 , RMSE =  0.0954391559885681 , DIR =  0.415 , BENCHMARK =  0.006515244912452403\n"," \n","cu_lme_prices_LD_22 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.009868450329009293 , RMSE =  0.0993400741343054 , DIR =  0.435 , BENCHMARK =  0.007022493609341893\n"," \n","cu_lme_prices_LD_22 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  150\n","MSE =  0.006381837980446789 , RMSE =  0.07988640673135067 , DIR =  0.495 , BENCHMARK =  0.0049162830973465575\n"," \n","cu_lme_prices_LD_22 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  50\n","MSE =  0.008912133774681828 , RMSE =  0.09440409829388674 , DIR =  0.495 , BENCHMARK =  0.007459809022064334\n"," \n","cu_lme_prices_LD_22 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  100\n","MSE =  0.007291722593446086 , RMSE =  0.08539158385605743 , DIR =  0.46 , BENCHMARK =  0.006252820158403174\n"," \n","cu_lme_prices_LD_22 , Kernel =  <class 'gpytorch.kernels.matern_kernel.MaternKernel'> , Window =  150\n","MSE =  0.007520267766662663 , RMSE =  0.08671947743536433 , DIR =  0.425 , BENCHMARK =  0.005171084475546941\n"," \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wT8uVIMmDaIA","colab_type":"text"},"source":["# Now Check Confidence Intervals"]},{"cell_type":"code","metadata":{"id":"FpChmaGo4CAq","colab_type":"code","colab":{}},"source":["def GET_STAT_CI(metal, Windows, Horizons, Target_Variables, Kernels, trials):\n","\n","  # metal is either 'al' or 'cu'\n","  \n","  I = len(Horizons)\n","  J = len(Kernels)\n","  K = len(Windows)\n","  \n","  MSE = np.zeros((I,J,K,trials))\n","  DIR = np.zeros((I,J,K,trials))\n","  BM = np.zeros((I,J,K,trials))\n","  PRED = np.zeros((I,J,K,trials))\n","  LOWER = np.zeros((I,J,K,trials))\n","  UPPER = np.zeros((I,J,K,trials))\n","\n","  for i,H_TV in enumerate(zip(Horizons, Target_Variables)):\n","    # horizon and target variable\n","    H = H_TV[0]\n","    TV = H_TV[1]\n","    \n","    DF = feature_generation(metal, time_pred = [1,5,22])\n","    DF = feature_extraction(DF, TV, H)\n","    \n","    \n","    # X is the predictors - all but the first column\n","    X = DF.iloc[:,1:]\n","    \n","    # Y is the target variable - just the first column\n","    Y = DF.iloc[:,[0]]\n","    \n","    ard_param = X.shape[1]\n","\n","    for j,Kernel in enumerate(Kernels):\n","      for k,Window in enumerate(Windows):\n","        for t in range(trials):\n","\n","          START = int(np.random.choice(np.arange(len(Y) - 200),1) )\n","          END = START + Window\n","          X_train = torch.tensor( X.iloc[START:END, :].values , dtype = torch.float32)\n","          X_test = torch.tensor( X.iloc[[END -1 + H], :].values , dtype = torch.float32)\n","          Y_train = torch.tensor( Y.iloc[START:END, :].values.T.squeeze() , dtype = torch.float32)\n","          Y_test = torch.tensor( Y.iloc[END -1 + H, :].values.T.squeeze() , dtype = torch.float32)\n","\n","          likelihood = gpytorch.likelihoods.GaussianLikelihood()\n","          model = ExactGPModel(X_train, Y_train, likelihood, Kernel(ard_num_dims = ard_param))\n","          model.train()\n","          likelihood.train()\n","\n","          # Use the adam optimizer\n","          optimizer = torch.optim.Adam([\n","              {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n","          ], lr=0.1)\n","\n","          # \"Loss\" for GPs - the marginal log likelihood\n","          mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n","          training_iter = 100\n","          for l in range(training_iter):\n","              optimizer.zero_grad()\n","              output = model(X_train)\n","              loss = -mll(output, Y_train)\n","              loss.backward()\n","              optimizer.step()\n","\n","          # Get into evaluation (predictive posterior) mode\n","          model.eval()\n","          likelihood.eval()\n","\n","          # Make predictions by feeding model through likelihood\n","          with torch.no_grad(), gpytorch.settings.fast_pred_var():\n","              observed_pred = likelihood(model(X_test))\n","          \n","          PRED[i,j,k,t] = observed_pred.mean.numpy()\n","          MSE[i,j,k,t] = (observed_pred.mean - Y_test).numpy()**2\n","          DIR[i,j,k,t] = (torch.sign(observed_pred.mean) == torch.sign(Y_test)).numpy()\n","          BM[i,j,k,t] = Y_test.numpy()**2\n","          \n","#           print(observed_pred.confidence_region())\n","          \n","          LOWER[i,j,k,t], UPPER[i,j,k,t] = torch.tensor(observed_pred.confidence_region()).detach().numpy()\n","          \n","        RANGE = UPPER - LOWER\n","        CONTAINED = (UPPER > Y_test.numpy()) * (Y_test.numpy() > LOWER)\n","\n","        print(TV, ', Kernel = ', str(Kernel),', Window = ', Window)\n","        print('MSE = ', np.mean(MSE[i,j,k,:]), \n","#               ', RMSE = ', np.mean(MSE[i,j,k,:])**0.5, \n","#               ', DIR = ', np.mean(DIR[i,j,k,:]), \n","#               ', BENCHMARK = ', np.mean(BM[i,j,k,:]),\n","              ', RANGE =', np.mean(RANGE[i,j,k,:]),\n","              ', CONTAINED =', np.mean(CONTAINED[i,j,k,:]))\n","        print(' ')\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaiWCjOEDWTq","colab_type":"code","outputId":"a3107c68-f566-4ee8-a5fa-5b5e24b5899e","executionInfo":{"status":"ok","timestamp":1565357170788,"user_tz":-60,"elapsed":317091,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":179}},"source":["metal = 'al'\n","Windows = [100]\n","Horizons = [1, 5, 22]\n","AL_Target_Variables = ['al_lme_prices_LD_1', 'al_lme_prices_LD_5', 'al_lme_prices_LD_22']\n","Kernels = [gpytorch.kernels.RBFKernel]\n","trials = 200\n","GET_STAT_CI(metal = metal, \n","            Windows = Windows, \n","            Horizons = Horizons, \n","            Target_Variables = AL_Target_Variables, \n","            Kernels = Kernels, \n","            trials = trials)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["al_lme_prices_LD_1 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.0002072676154255948 , RANGE = 0.06259431147016585 , CONTAINED = 1.0\n"," \n","al_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.002055889971808327 , RANGE = 0.11976522130891681 , CONTAINED = 0.945\n"," \n","al_lme_prices_LD_22 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.0069425240296286 , RANGE = 0.2533969273418188 , CONTAINED = 0.95\n"," \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C4HFZtEMIKRj","colab_type":"code","outputId":"f42a3d1a-7208-4fef-8024-7af4616c397f","executionInfo":{"status":"ok","timestamp":1565349247524,"user_tz":-60,"elapsed":324231,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":179}},"source":["metal = 'cu'\n","Windows = [100]\n","Horizons = [1, 5, 22]\n","CU_Target_Variables = ['cu_lme_prices_LD_1', 'cu_lme_prices_LD_5', 'cu_lme_prices_LD_22']\n","Kernels = [gpytorch.kernels.RBFKernel]\n","trials = 200\n","GET_STAT_CI(metal = metal, \n","            Windows = Windows, \n","            Horizons = Horizons, \n","            Target_Variables = CU_Target_Variables, \n","            Kernels = Kernels, \n","            trials = trials)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cu_lme_prices_LD_1 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.0004293172152149083 , RANGE = 0.07333154259249568 , CONTAINED = 1.0\n"," \n","cu_lme_prices_LD_5 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.002062577247382045 , RANGE = 0.1420283438079059 , CONTAINED = 0.95\n"," \n","cu_lme_prices_LD_22 , Kernel =  <class 'gpytorch.kernels.rbf_kernel.RBFKernel'> , Window =  100\n","MSE =  0.009439926407515174 , RANGE = 0.2808407737314701 , CONTAINED = 0.94\n"," \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LH4Y5aggyKJr","colab_type":"text"},"source":["# Checking validity of self implementation of GP"]},{"cell_type":"code","metadata":{"id":"oSt2JZ1weX7f","colab_type":"code","outputId":"a75dac2e-76e4-4d2a-f44c-9883ddec8e1a","executionInfo":{"status":"ok","timestamp":1565923758050,"user_tz":-60,"elapsed":26720,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}},"colab":{"base_uri":"https://localhost:8080/","height":503}},"source":["\n","def Check_GP_implementation(metal, Window, Horizon, Target_Variables, trials):\n","\n","  # metal is either 'al' or 'cu'\n","  \n","  for i,H_TV in enumerate(zip(Horizons, Target_Variables)):\n","  \n","    H = H_TV[0]\n","    TV = H_TV[1]\n","\n","    DF = feature_generation(metal, time_pred = [1,5,22])\n","    DF = feature_extraction(DF, TV, H)\n","\n","    # X is the predictors - all but the first column\n","    X = DF.iloc[:,1:]\n","\n","    # Y is the target variable - just the first column\n","    Y = DF.iloc[:,[0]]\n","\n","    chosen = np.random.choice(np.arange(len(Y) - 200), trials, replace = False) \n","\n","    for t in range(trials):\n","      START = chosen[t]\n","      END = START + Window\n","      train_x = torch.tensor( X.iloc[START:END, :].values , dtype = torch.float32)\n","      test_x  = torch.tensor( X.iloc[[END -1 + H], :].values , dtype = torch.float32)\n","      train_y = torch.tensor( Y.iloc[START:END, :].values.T.squeeze() , dtype = torch.float32)\n","      test_y  = torch.tensor( Y.iloc[END -1 + H, :].values.T.squeeze() , dtype = torch.float32)\n","      \n","      print('default ', GP_train_default(train_x,train_y,test_x,test_y))\n","      print('own ', GP_train_own(train_x,train_y,test_x,test_y))\n","      \n","      \n","CU_Target_Variables = ['cu_lme_prices_LD_1', 'cu_lme_prices_LD_5', 'cu_lme_prices_LD_22']\n","    \n","    \n","Check_GP_implementation(metal = 'cu', \n","                        Window = 100, \n","                        Horizon = [1,5,22],  \n","                        Target_Variables = CU_Target_Variables, \n","                        trials = 3)\n","        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["default  7.9078045e-06\n","torch.Size([1, 100])\n","own  1.849955e-05\n","default  0.002319852\n","torch.Size([1, 100])\n","own  0.0043498552\n","default  3.6036786e-06\n","torch.Size([1, 100])\n","own  3.6918893e-05\n","default  9.7894525e-05\n","torch.Size([1, 100])\n","own  0.000851229\n","default  8.337552e-06\n","torch.Size([1, 100])\n","own  0.00024062477\n","default  0.00047345008\n","torch.Size([1, 100])\n","own  0.00068953616\n","default  0.017755324\n","torch.Size([1, 100])\n","own  0.03177424\n","default  0.015353109\n","torch.Size([1, 100])\n","own  0.117191836\n","default  0.010456841\n","torch.Size([1, 100])\n","own  0.05559313\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dLy8uA4IH5-E","colab_type":"code","colab":{}},"source":["class ExactGPModel(gpytorch.models.ExactGP):\n","    def __init__(self, train_x, train_y, likelihood):\n","        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n","        self.mean_module = gpytorch.means.ConstantMean()\n","        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims = train_x.shape[1]))\n","\n","    def forward(self, x):\n","        mean_x = self.mean_module(x)\n","        covar_x = self.covar_module(x)\n","        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n","\n","def softplus(param):\n","    return torch.log(1 + torch.exp(param) )\n","\n","class RBF:\n","    def __init__(self, dimensions, ARD = False):\n","        self.sigma = torch.nn.Parameter(torch.rand(dimensions)) \n","        self.ARD = ARD\n","        self.params = [self.sigma]\n","    \n","    def forward(self, x, y):\n","        '''\n","        x and y must be of dimensions N x feature_space \n","        '''\n","        assert x.shape[1] == y.shape[1]\n","        \n","        result = torch.exp(-torch.norm((x.unsqueeze(1) - y.unsqueeze(0)) / softplus(self.sigma[None,None,:]), dim = 2) ** 2)\n","        return result\n","\n","class GP: #simultaneous independent GP\n","    def __init__(self, X, Y, kernel, ARD):\n","        # X has size N x DIM\n","        # Y has size N X tasks\n","        self.X = X\n","        self.Y = Y\n","        self.kernel = kernel(self.X.shape[1],ARD) \n","        \n","        # initialize parameters\n","        self.noise = torch.nn.Parameter(torch.rand(1) ) \n","\n","    def get_params(self):\n","        return([self.noise] + self.kernel.params)\n","    \n","    def get_cov(self):\n","        return self.kernel.forward(self.X, self.X) + softplus(self.noise) * torch.eye(len(self.X))\n","        \n","    \n","    def get_K_xX(self, x):\n","        return self.kernel.forward(x, self.X) \n","    \n","    def get_K_xx(self, x):\n","        return self.kernel.forward(x, x) +   softplus(self.noise) * torch.eye(len(x))\n","    \n","class Likelihood:\n","    def __init__(self):\n","        pass\n","    \n","    def forward(self, K, Y):\n","        Cholesky = torch.cholesky(K)\n","        \n","        Likelihood = 0.5*2*torch.sum(torch.log(torch.diag(Cholesky))) \\\n","            + 0.5* (Y[None,:]).mm(torch.solve(Y[:,None],K)[0] )\n","        return Likelihood\n","  \n","\n","def predict(X, Y, x, GP_model):\n","\n","    K_XX = GP_model.get_cov()\n","    K_xX = GP_model.get_K_xX(x)\n","    K_xx = GP_model.get_K_xx(x)\n","    print(K_xX.shape)\n","    pred_mean = K_xX.mm(torch.solve(Y[:,None],K_XX)[0] ).squeeze()\n","    pred_cov = K_xx - K_xX.mm(torch.solve(K_xX.t(), K_XX)[0])\n","\n","    return(pred_mean, pred_cov)\n","\n","def GP_train_default(train_x,train_y,test_x,test_y):  \n","  \n","    train_y = train_y.squeeze()\n","    test_y = test_y.squeeze()\n","    \n","    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n","    model = ExactGPModel(train_x, train_y, likelihood)\n","    \n","    model.train()\n","    likelihood.train()\n","\n","    # Use the adam optimizer\n","    optimizer = torch.optim.Adam([\n","        {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n","    ], lr=0.1)\n","\n","    # \"Loss\" for GPs - the marginal log likelihood\n","    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n","    \n","    training_iter = 100\n","    for i in range(training_iter):\n","        # Zero gradients from previous iteration\n","        optimizer.zero_grad()\n","        # Output from model\n","        \n","        output = model(train_x)\n","        # Calc loss and backprop gradients\n","        \n","        \n","        loss = -mll(output, train_y)\n","        loss.backward()\n","        optimizer.step()\n","        \n","    model.eval()\n","    likelihood.eval()\n","    \n","    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n","        test_x = test_x\n","        observed_pred = likelihood(model(test_x))\n","        \n","    y_pred = observed_pred.mean.detach().numpy()\n","\n","    return np.mean((y_pred - test_y.numpy())**2 )\n","        \n","        \n","def GP_train_own(train_x,train_y,test_x,test_y):\n","    GP1 = GP(train_x, train_y, kernel = RBF, ARD = False)\n","    \n","    LLH = Likelihood()\n","    \n","    optimizer = torch.optim.Adam(params = GP1.get_params(), \n","                                 lr = 0.1)\n","    for i in range(100):\n","      \n","      K = GP1.get_cov()\n","      loss = LLH.forward(K, GP1.Y)\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","    \n","\n","    return torch.mean((predict(train_x, train_y, test_x, GP1)[0] - test_y)**2).detach().numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjFwanaSSTN3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tGfEf7IJ4Wty","colab_type":"text"},"source":["# Just some pictures"]},{"cell_type":"code","metadata":{"id":"muPHc0Xv4YQ4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":903},"outputId":"776abc88-22c5-4058-e478-c2736561db70","executionInfo":{"status":"ok","timestamp":1566601018016,"user_tz":-60,"elapsed":489,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}}},"source":["import math\n","# Training data is 11 points in [0,1] inclusive regularly spaced\n","train_x = torch.linspace(0, 1, 4)\n","# True function is sin(2*pi*x) with Gaussian noise\n","train_y = torch.sin(train_x * (2 * math.pi)) #+ torch.randn(train_x.size()) * 0.2\n","\n","class ExactGPModel(gpytorch.models.ExactGP):\n","    def __init__(self, train_x, train_y, likelihood):\n","        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n","        self.mean_module = gpytorch.means.ConstantMean()\n","        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n","\n","    def forward(self, x):\n","        mean_x = self.mean_module(x)\n","        covar_x = self.covar_module(x)\n","        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n","\n","# initialize likelihood and model\n","likelihood = gpytorch.likelihoods.GaussianLikelihood()\n","model = ExactGPModel(train_x, train_y, likelihood)\n","\n","# Find optimal model hyperparameters\n","model.train()\n","likelihood.train()\n","\n","\n","# Use the adam optimizer\n","optimizer = torch.optim.Adam([\n","    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n","], lr=0.1)\n","\n","# \"Loss\" for GPs - the marginal log likelihood\n","mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n","\n","training_iter = 50\n","for i in range(training_iter):\n","    # Zero gradients from previous iteration\n","    optimizer.zero_grad()\n","    # Output from model\n","    output = model(train_x)\n","    # Calc loss and backprop gradients\n","    loss = -mll(output, train_y)\n","    loss.backward()\n","    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n","        i + 1, training_iter, loss.item(),\n","        model.covar_module.base_kernel.lengthscale.item(),\n","        model.likelihood.noise.item()\n","    ))\n","    optimizer.step()"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Iter 1/50 - Loss: 1.247   lengthscale: 0.693   noise: 0.693\n","Iter 2/50 - Loss: 1.227   lengthscale: 0.744   noise: 0.644\n","Iter 3/50 - Loss: 1.210   lengthscale: 0.798   noise: 0.599\n","Iter 4/50 - Loss: 1.192   lengthscale: 0.854   noise: 0.556\n","Iter 5/50 - Loss: 1.178   lengthscale: 0.912   noise: 0.517\n","Iter 6/50 - Loss: 1.166   lengthscale: 0.972   noise: 0.483\n","Iter 7/50 - Loss: 1.154   lengthscale: 1.033   noise: 0.456\n","Iter 8/50 - Loss: 1.144   lengthscale: 1.095   noise: 0.436\n","Iter 9/50 - Loss: 1.134   lengthscale: 1.157   noise: 0.424\n","Iter 10/50 - Loss: 1.124   lengthscale: 1.220   noise: 0.420\n","Iter 11/50 - Loss: 1.114   lengthscale: 1.282   noise: 0.421\n","Iter 12/50 - Loss: 1.104   lengthscale: 1.343   noise: 0.426\n","Iter 13/50 - Loss: 1.094   lengthscale: 1.402   noise: 0.435\n","Iter 14/50 - Loss: 1.085   lengthscale: 1.459   noise: 0.445\n","Iter 15/50 - Loss: 1.077   lengthscale: 1.514   noise: 0.455\n","Iter 16/50 - Loss: 1.069   lengthscale: 1.567   noise: 0.465\n","Iter 17/50 - Loss: 1.063   lengthscale: 1.616   noise: 0.471\n","Iter 18/50 - Loss: 1.056   lengthscale: 1.663   noise: 0.475\n","Iter 19/50 - Loss: 1.049   lengthscale: 1.707   noise: 0.475\n","Iter 20/50 - Loss: 1.043   lengthscale: 1.749   noise: 0.472\n","Iter 21/50 - Loss: 1.036   lengthscale: 1.787   noise: 0.466\n","Iter 22/50 - Loss: 1.030   lengthscale: 1.823   noise: 0.457\n","Iter 23/50 - Loss: 1.024   lengthscale: 1.856   noise: 0.447\n","Iter 24/50 - Loss: 1.018   lengthscale: 1.887   noise: 0.436\n","Iter 25/50 - Loss: 1.013   lengthscale: 1.916   noise: 0.425\n","Iter 26/50 - Loss: 1.008   lengthscale: 1.942   noise: 0.416\n","Iter 27/50 - Loss: 1.004   lengthscale: 1.966   noise: 0.408\n","Iter 28/50 - Loss: 1.000   lengthscale: 1.989   noise: 0.403\n","Iter 29/50 - Loss: 0.996   lengthscale: 2.009   noise: 0.400\n","Iter 30/50 - Loss: 0.992   lengthscale: 2.027   noise: 0.399\n","Iter 31/50 - Loss: 0.988   lengthscale: 2.044   noise: 0.401\n","Iter 32/50 - Loss: 0.984   lengthscale: 2.060   noise: 0.403\n","Iter 33/50 - Loss: 0.981   lengthscale: 2.074   noise: 0.406\n","Iter 34/50 - Loss: 0.978   lengthscale: 2.086   noise: 0.410\n","Iter 35/50 - Loss: 0.976   lengthscale: 2.098   noise: 0.413\n","Iter 36/50 - Loss: 0.973   lengthscale: 2.108   noise: 0.414\n","Iter 37/50 - Loss: 0.971   lengthscale: 2.117   noise: 0.414\n","Iter 38/50 - Loss: 0.968   lengthscale: 2.126   noise: 0.413\n","Iter 39/50 - Loss: 0.966   lengthscale: 2.133   noise: 0.410\n","Iter 40/50 - Loss: 0.964   lengthscale: 2.140   noise: 0.406\n","Iter 41/50 - Loss: 0.962   lengthscale: 2.146   noise: 0.402\n","Iter 42/50 - Loss: 0.961   lengthscale: 2.151   noise: 0.397\n","Iter 43/50 - Loss: 0.959   lengthscale: 2.156   noise: 0.393\n","Iter 44/50 - Loss: 0.958   lengthscale: 2.160   noise: 0.390\n","Iter 45/50 - Loss: 0.956   lengthscale: 2.164   noise: 0.387\n","Iter 46/50 - Loss: 0.955   lengthscale: 2.167   noise: 0.386\n","Iter 47/50 - Loss: 0.954   lengthscale: 2.169   noise: 0.386\n","Iter 48/50 - Loss: 0.953   lengthscale: 2.172   noise: 0.387\n","Iter 49/50 - Loss: 0.952   lengthscale: 2.174   noise: 0.389\n","Iter 50/50 - Loss: 0.951   lengthscale: 2.175   noise: 0.391\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MewWeXuFMMfE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"outputId":"6d87bf26-b7fa-4a58-bd3f-c6425c6ebff9","executionInfo":{"status":"ok","timestamp":1566601020399,"user_tz":-60,"elapsed":689,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}}},"source":["# Get into evaluation (predictive posterior) mode\n","model.eval()\n","likelihood.eval()\n","\n","# Test points are regularly spaced along [0,1]\n","# Make predictions by feeding model through likelihood\n","with torch.no_grad(), gpytorch.settings.fast_pred_var():\n","    test_x = torch.linspace(0, 1, 100)\n","    observed_pred = likelihood(model(test_x))\n","    \n","with torch.no_grad():\n","    # Initialize plot\n","    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n","\n","    # Get upper and lower confidence bounds\n","    lower, upper = observed_pred.confidence_region()\n","    # Plot training data as black stars\n","    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n","    # Plot predictive means as blue line\n","    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n","    # Shade between the lower and upper confidence bounds\n","    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n","    ax.set_ylim([-3, 3])\n","    ax.legend(['Observed Data', 'Mean', 'Confidence'])"],"execution_count":46,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQYAAADGCAYAAAAwqi48AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAwiEqBgEJEABYOIBCgYRCTg/wOTRDjB8QxOTAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 288x216 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"qnep1PZ-Mfn5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":159},"outputId":"323f08a5-cd90-49b7-b092-67c0a0980f24","executionInfo":{"status":"ok","timestamp":1566600660774,"user_tz":-60,"elapsed":498,"user":{"displayName":"winter hand","photoUrl":"","userId":"01747296189247204151"}}},"source":["for name, data in model.named_parameters():\n","  print(name, data)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["likelihood.noise_covar.raw_noise Parameter containing:\n","tensor([-13.6386], requires_grad=True)\n","mean_module.constant Parameter containing:\n","tensor([-4.7407e-05], requires_grad=True)\n","covar_module.raw_outputscale Parameter containing:\n","tensor(2.2626, requires_grad=True)\n","covar_module.base_kernel.raw_lengthscale Parameter containing:\n","tensor([[-0.7638]], requires_grad=True)\n"],"name":"stdout"}]}]}